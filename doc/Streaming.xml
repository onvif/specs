<?xml version="1.0"?>
<?xml-stylesheet href="docbook.xsl" type="text/xsl" ?>
<book xmlns="http://docbook.org/ns/docbook" version="5.0">
  <info>
    <title>Streaming Specification</title>
    <titleabbrev>Streaming</titleabbrev>
    <releaseinfo>21.06</releaseinfo>
    <author>
      <orgname>ONVIF™</orgname>
      <uri>www.onvif.org</uri>
    </author>
    <pubdate>June, 2021</pubdate>
    <mediaobject>
      <imageobject>
        <imagedata fileref="media/logo.png" contentwidth="60mm"/>
      </imageobject>
    </mediaobject>
    <copyright>
      <year>2008-2021</year>
      <holder>ONVIF™ All rights reserved.</holder>
    </copyright>
    <legalnotice>
      <para>Recipients of this document may copy, distribute, publish, or display this document so
        long as this copyright notice, license and disclaimer are retained with all copies of the
        document. No license is granted to modify this document.</para>
      <para>THIS DOCUMENT IS PROVIDED "AS IS," AND THE CORPORATION AND ITS MEMBERS AND THEIR
        AFFILIATES, MAKE NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT
        LIMITED TO, WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE,
        NON-INFRINGEMENT, OR TITLE; THAT THE CONTENTS OF THIS DOCUMENT ARE SUITABLE FOR ANY PURPOSE;
        OR THAT THE IMPLEMENTATION OF SUCH CONTENTS WILL NOT INFRINGE ANY PATENTS, COPYRIGHTS,
        TRADEMARKS OR OTHER RIGHTS.</para>
      <para>IN NO EVENT WILL THE CORPORATION OR ITS MEMBERS OR THEIR AFFILIATES BE LIABLE FOR ANY
        DIRECT, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE OR CONSEQUENTIAL DAMAGES, ARISING OUT OF OR
        RELATING TO ANY USE OR DISTRIBUTION OF THIS DOCUMENT, WHETHER OR NOT (1) THE CORPORATION,
        MEMBERS OR THEIR AFFILIATES HAVE BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES, OR (2)
        SUCH DAMAGES WERE REASONABLY FORESEEABLE, AND ARISING OUT OF OR RELATING TO ANY USE OR
        DISTRIBUTION OF THIS DOCUMENT.  THE FOREGOING DISCLAIMER AND LIMITATION ON LIABILITY DO NOT
        APPLY TO, INVALIDATE, OR LIMIT REPRESENTATIONS AND WARRANTIES MADE BY THE MEMBERS AND THEIR
        RESPECTIVE AFFILIATES TO THE CORPORATION AND OTHER MEMBERS IN CERTAIN WRITTEN POLICIES OF
        THE CORPORATION.</para>
    </legalnotice>
    <revhistory>
      <revision>
        <revnumber>2.1</revnumber>
        <date>Jul-2011</date>
        <author>
          <personname>Hans Busch</personname>
        </author>
        <revremark>Split from Core 2.0 Change Requests 201, 225</revremark>
      </revision>
      <revision>
        <revnumber>2.1.1</revnumber>
        <date>Jan-2012</date>
        <author>
          <personname>Hans Busch</personname>
        </author>
        <revremark>Change Requests 282, 283, 284, 296, 289, 290, 264, 316, 333, 549</revremark>
      </revision>
      <revision>
        <revnumber>2.2</revnumber>
        <date>May-2012</date>
        <author>
          <personname>Hans Busch</personname>
        </author>
        <revremark>Change Request 613</revremark>
      </revision>
      <revision>
        <revnumber>2.2.1</revnumber>
        <date>Dec-2012</date>
        <author>
          <personname>Michio Hirai</personname>
        </author>
        <revremark>Change Requests 768, 878</revremark>
      </revision>
      <revision>
        <revnumber>2.3</revnumber>
        <date>May-2013</date>
        <author>
          <personname>Michio Hirai</personname>
        </author>
        <revremark>Change Request 1051</revremark>
      </revision>
      <revision>
        <revnumber>2.4.1</revnumber>
        <date>Dec-2013</date>
        <author>
          <personname>Michio Hirai</personname>
        </author>
        <revremark>Change Request 1285</revremark>
      </revision>
      <revision>
        <revnumber>2.4.2</revnumber>
        <date>Jun-2014</date>
        <author>
          <personname>Michio Hirai</personname>
        </author>
        <revremark>Change Request 1323</revremark>
      </revision>
      <revision>
        <revnumber>2.5</revnumber>
        <date>Dec-2014</date>
        <author>
          <personname>Hans Busch</personname>
        </author>
        <author>
          <personname>Michio Hirai</personname>
        </author>
        <revremark>Added support for gzip compressed metadata Change Request 1443</revremark>
      </revision>
      <revision>
        <revnumber>2.6</revnumber>
        <date>Jun-2015</date>
        <author>
          <personname>Michio Hirai</personname>
        </author>
        <revremark>Change Request 1571, 1605, 1624</revremark>
      </revision>
      <revision>
        <revnumber>16.06</revnumber>
        <date>Jun-2016</date>
        <author>
          <personname>Hiroyuki Sano</personname>
        </author>
        <revremark>Change Request 1717, 1725, 1852</revremark>
      </revision>
      <revision>
        <revnumber>16.12</revnumber>
        <date>Dec-2016</date>
        <author>
          <personname>Sujith Raman</personname>
        </author>
        <author>
          <personname>Hans Busch</personname>
        </author>
        <author>
          <personname>Hiroyuki Sano</personname>
        </author>
        <revremark>Added RTSP over WebSocket Change Request 1886, 1888, 1890</revremark>
      </revision>
      <revision>
        <revnumber>17.06</revnumber>
        <date>Jun-2017</date>
        <author>
          <personname>Hiroyuki Sano</personname>
        </author>
        <revremark>Change Request 1843, 1954, 1997, 2084, 2085, 2128</revremark>
      </revision>
      <revision>
        <revnumber>17.12</revnumber>
        <date>Dec-2017</date>
        <author>
          <personname>Hiroyuki Sano</personname>
        </author>
        <revremark>Change Request 2165, 2180, 2181, 2206, 2210</revremark>
      </revision>
      <revision>
        <revnumber>18.06</revnumber>
        <date>Jun-2018</date>
        <author>
          <personname>Hiroyuki Sano</personname>
        </author>
        <revremark>Change Request 2229, 2247, 2254, 2275, 2284, 2285</revremark>
      </revision>
      <revision>
        <revnumber>19.06</revnumber>
        <date>Jun-2019</date>
        <author>
          <personname>Hiroyujki Sano</personname>
        </author>
        <revremark>Change Request 2446, 2464</revremark>
      </revision>
      <revision>
        <revnumber>19.12</revnumber>
        <date>Dec-2019</date>
        <author>
          <personname>Dora Han</personname>
        </author>
        <revremark>Added Multitrack Streaming</revremark>
      </revision>
      <revision>
        <revnumber>21.06</revnumber>
        <date>Jun-2021</date>
        <author>
          <personname>Hans Busch</personname>
        </author>
        <revremark>Improve section on timeout and keep-alive handling.</revremark>
      </revision>
    </revhistory>
  </info>
  <chapter>
    <title>Scope</title>
    <para>This document defines the ONVIF specific streaming extensions for live and replay streaming. The corresponding web service APIs to retrieve the streaming URIs are defined in separate documents and are not covered in this document.</para>
  </chapter>
  <chapter>
    <title>Normative references</title>
    <para>ISO/IEC 14496-2:2004, <emphasis>Information technology -- Coding of audio-visual objects -- Part 2: Visual</emphasis></para>
    <para>ISO/IEC 14496-3:2005, <emphasis>Information technology -- Coding of audio-visual objects -- Part 3: Audio</emphasis></para>
    <para>ISO/IEC 14496-10:2008, <emphasis>Information technology -- Coding of audio-visual objects -- Part 10: Advanced Video Coding</emphasis></para>
    <para>ISO/IEC 23008-2:2015,<emphasis> Information technology -- High efficiency coding and media delivery in heterogeneous environments -- Part 2: High efficiency video coding</emphasis></para>
    <para role="reference">ITU-T G.711, <emphasis>Pulse code modulation (PCM) of voice frequencies</emphasis>  &lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href=""> http://www.itu.int/rec/dologin_pub.asp?lang=e&amp;id=T-REC-G.711-198811-I!!PDF-E&amp;type=items</link>&gt;</para>
    <para>ITU-T G.726,<emphasis> 40, 32, 24, 16 kbit/s Adaptive Differential Pulse Code Modulation (ADPCM)</emphasis></para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.itu.int/rec/dologin_pub.asp?lang=e&amp;id=T-REC-G.726-199012-I!!PDF-E&amp;type=items</link>&gt;</para>
    <para>RSA Laboratories, PKCS #10 v1.7: <emphasis>Certification Request Syntax Standard, RSA Laboratories</emphasis></para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">ftp://ftp.rsasecurity.com/pub/pkcs/pkcs-10/pkcs-10v1_7.pdf</link>&gt;</para>
    <para>IETF RFC 2246, The TLS Protocol Version 1.0</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc2246.txt</link>&gt;</para>
    <para>IETF RFC 2326, Real Time Streaming Protocol (RTSP)</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc2326.txt</link>&gt;</para>
    <para>IETF RFC 2396, Uniform Resource Identifiers (URI): General Syntax</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc2396.txt</link>&gt;</para>
    <para>IETF RFC 2435, RFC2435 - RTP Payload Format for JPEG-compressed Video</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc2435.txt</link>&gt;</para>
    <para>IETF RFC 3016, RTP Payload Format for MPEG-4 Audio/Visual Streams</para>
    <programlisting><![CDATA[http://www.ietf.org/rfc/rfc3016.txt
]]></programlisting>
    <para>IETF RFC 3550, RTP: A Transport Protocol for Real-Time Applications</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc3550.txt</link>&gt;</para>
    <para>IETF RFC 3551, RTP Profile for Audio and Video Conferences  with Minimal Control</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc3551.txt</link>&gt;</para>
    <para>IETF RFC 3640, RTP Payload Format for Transport of MPEG-4 Elementary Streams</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc3640.txt</link>&gt;</para>
    <para>IETF RFC 3984, RTP Payload Format for H.264 Video</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc3984</link>&gt;</para>
    <para>IETF RFC 3016, RTP Payload Format for MPEG-4 Audio/Visual Streams</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc3016</link>&gt;</para>
    <para>IETF RFC 4566, SDP: Session Description Protocol</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc4566.txt</link>&gt;</para>
    <para>IETF RFC 4571, Framing Real-time Transport Protocol (RTP) and RTP Control Protocol (RTCP) Packets over Connection-Oriented Transport</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc4571.txt</link>&gt;</para>
    <para>IETF RFC 4585, Extended RTP Profile for Real-time Transport Control Protocol (RTCP)-Based Feedback (RTP/AVPF)</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc4585.txt</link>&gt;</para>
    <para>IETF  5104, Codec Control Messages in the RTP Audio-Visual Profile with Feedback (AVPF)</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc5104.txt</link>&gt;</para>
    <para>IETF RFC 5888 The Session Description Protocol (SDP) Grouping Framework</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">https:/tools.ietf.org/html/rfc5888</link>&gt;</para>
    <para>IETF RFC 6455, The WebSocket Protocol</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc6455.txt</link>&gt;</para>
    <para>IETF RFC 7798, RTP Payload Format for High Efficiency Video Coding (HEVC)</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc7798.txt</link>&gt;</para>
    <para>IETF RFC 7826, Real-Time Streaming Protocol Version 2.0</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.ietf.org/rfc/rfc7826.txt</link>&gt;</para>
    <para>GZIP file format specification version 4.3</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://tools.ietf.org/html/rfc1952</link>&gt;</para>
    <para>Apple Computer Inc. RTSP over HTTP, Tunneling QuickTime RTSP and RTP over HTTP</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">https://opensource.apple.com/source/QuickTimeStreamingServer/QuickTimeStreamingServer-412.42/Documentation/RTSP_Over_HTTP.pdf</link>&gt;</para>
    <para>ONVIF Core Specification</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.onvif.org/specs/core/ONVIF-Core-Specification.pdf</link>&gt;</para>
    <para>ONVIF Media Service Specification</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.onvif.org/specs/srv/media/ONVIF-Media-Service-Spec.pdf</link>&gt;</para>
    <para>ONVIF Media2 Service Specification</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">http://www.onvif.org/specs/srv/media/ONVIF-Media2-Service-Spec.pdf</link>&gt;</para>
    <para>ONVIF Replay Control Service Specification</para>
    <para role="reference">&lt;<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="">https://www.onvif.org/specs/srv/replay/ONVIF-ReplayControl-Service-Spec.pdf</link>&gt;</para>
  </chapter>
  <chapter>
    <title>Terms and Definitions</title>
    <section>
      <title>Definitions</title>
      <informaltable>
        <tgroup cols="2">
          <colspec colname="c1" colwidth="24*" />
          <colspec colname="c2" colwidth="76*" />
          <tbody valign="top">
            <row>
              <entry align="left">
                <para>
                  <emphasis role="bold">Access Unit</emphasis>
                </para>
              </entry>
              <entry align="left">
                <para>One or more frames or samples of audio, video, or metadata which are contained in a group of RTP packets having the same presentation time.</para>
              </entry>
            </row>
            <row>
              <entry align="left">
                <para>
                  <emphasis role="bold">Metadata</emphasis>
                </para>
              </entry>
              <entry align="left">
                <para>All streaming data except video and audio, including video analytics results, PTZ position data and other <phrase>metadata (such as textual data from POS applications)</phrase>.</para>
              </entry>
            </row>
            <row>
              <entry align="left">
                <para>
                  <emphasis role="bold">Recording</emphasis>
                </para>
              </entry>
              <entry align="left">
                <para>Represents the currently stored media (if any) and metadata on the NVS from a single data source. A recording comprises one or more tracks. A recording can have more than one track of the same type e.g. two different video tracks recorded in parallel with different settings</para>
              </entry>
            </row>
            <row>
              <entry align="left">
                <para>
                  <emphasis role="bold">Track</emphasis>
                </para>
              </entry>
              <entry align="left">
                <para>An individual data channel consisting of video, audio, or metadata. This definition is consistent with the definition of track in [RFC 2326]</para>
              </entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
    </section>
    <section>
      <title>Abbreviations</title>
      <informaltable>
        <tgroup cols="2">
          <colspec colname="c1" colwidth="24*" />
          <colspec colname="c2" colwidth="76*" />
          <tbody valign="top">
            <row>
              <entry valign="middle">
                <para>AAC</para>
              </entry>
              <entry valign="middle">
                <para>Advanced Audio Coding</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>EOI</para>
              </entry>
              <entry valign="middle">
                <para>End Of Image</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>HEVC</para>
              </entry>
              <entry valign="middle">
                <para>High Efficiency Video Coding also coined H.265</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>JFIF</para>
              </entry>
              <entry valign="middle">
                <para>JPEG File Interchange Format </para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>JPEG</para>
              </entry>
              <entry valign="middle">
                <para>Joint Photographic Expert Group</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>MPEG-4</para>
              </entry>
              <entry valign="middle">
                <para>Moving Picture Experts Group - 4</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>PTZ</para>
              </entry>
              <entry valign="middle">
                <para>Pan/Tilt/Zoom</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>RTCP</para>
              </entry>
              <entry valign="middle">
                <para>RTP Control Protocol</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>RTP</para>
              </entry>
              <entry valign="middle">
                <para>Realtime Transport Protocol</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>RTSP</para>
              </entry>
              <entry valign="middle">
                <para>Real Time Streaming Protocol</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>SDP</para>
              </entry>
              <entry valign="middle">
                <para>Session Description Protocol</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>SOI</para>
              </entry>
              <entry valign="middle">
                <para>Start Of Image </para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>SOF</para>
              </entry>
              <entry valign="middle">
                <para>Start Of Frame</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>SOS</para>
              </entry>
              <entry valign="middle">
                <para>Start Of Scan</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>TCP</para>
              </entry>
              <entry valign="middle">
                <para>Transmission Control Protocol</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>UDP</para>
              </entry>
              <entry valign="middle">
                <para>User Datagram Protocol</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>UTC</para>
              </entry>
              <entry valign="middle">
                <para>Coordinated Universal Time</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>UTF</para>
              </entry>
              <entry valign="middle">
                <para>Unicode Transformation Format</para>
              </entry>
            </row>
            <row>
              <entry valign="middle">
                <para>EXI</para>
              </entry>
              <entry valign="middle">
                <para>Efficient XML Interchange Format</para>
              </entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
    </section>
  </chapter>
  <chapter>
    <title>Overview</title>
    <figure xml:id="_Ref213819468">
      <title>Layer structure</title>
      <mediaobject>
        <imageobject>
          <imagedata fileref="media/Streaming/image2.svg" contentwidth="160.6mm" contentdepth="121.4mm" />
        </imageobject>
      </mediaobject>
    </figure>
    <para>This standard defines media streaming options and formats. A distinction is made between <emphasis>media plane </emphasis>and <emphasis>control plane,</emphasis> as illustrated in <xref linkend="_Ref213819468" />. A set of media streaming (audio, video and meta data) options, all based on RTP [RFC 3550], are described in order to provide interoperable media streaming services.</para>
    <para>The metadata streaming container format allows well-defined, real-time streaming of analytics, PTZ status and notification data.</para>
    <para>Media configuration is done over SOAP/HTTP and is covered by the media configuration service as discussed in Section 4.6. </para>
    <para>Media control is accomplished over RTSP as defined in RFC 2326. This standard utilizes RTP, RTCP and RTSP profiling, as well as JPEG over RTP extensions and multicast control mechanisms.</para>
    <para>The standard introduces extensions to the RTSP standard to allow bi-directional streaming connections.</para>
    <para>Streaming configurations for the following video codecs are provided:</para>
    <itemizedlist>
      <listitem>
        <para>JPEG (over RTP), see <xref linkend="_Ref289166764" /><phrase>.</phrase></para>
      </listitem>
      <listitem>
        <para>MPEG-4, Simple Profile (SP) [ISO 14496-2] </para>
      </listitem>
      <listitem>
        <para>MPEG-4, Advanced Simple Profile (ASP) [ISO 14496-2] </para>
      </listitem>
      <listitem>
        <para>H.264, baseline [ISO 14496-10] </para>
      </listitem>
      <listitem>
        <para>H.264, main [ISO 14496-10] </para>
      </listitem>
      <listitem>
        <para>H.264, extended [ISO 14496-10] </para>
      </listitem>
      <listitem>
        <para>H.264, high [ISO 14496-10] </para>
      </listitem>
      <listitem>
        <para>HEVC [ISO23008-2]</para>
      </listitem>
    </itemizedlist>
    <para>and for the following audio codecs:</para>
    <itemizedlist>
      <listitem>
        <para>G.711 [ITU-T G.711 uLaw]</para>
      </listitem>
      <listitem>
        <para>G.726 [ITU-T G.726]</para>
      </listitem>
      <listitem>
        <para>AAC [ISO 14496-3]</para>
      </listitem>
    </itemizedlist>
  </chapter>
  <chapter xml:id="_Toc208657708">
    <title>Live Streaming</title>
    <para>This section describes real-time streaming of video, audio and metadata. There is <emphasis>no specific </emphasis>service associated with the real-time streaming. The real-time configurations via Web Service commands are defined in the Media Service and the ReceiverService.</para>
    <section>
      <title>Media stream protocol</title>
      <section>
        <title>Transport format</title>
        <para>Real-time Transport Protocol (RTP) is a media transfer protocol (see Section <xref linkend="_Ref474396811" />). The following four sections describe RTP data transfer.</para>
        <section>
          <title>RTP data transfer via UDP</title>
          <para>UDP has the smallest overhead and is able to transfer real-time data in an efficient manner. A device shall support the RTP/UDP protocol and the device should support RTP/UDP multicasting.</para>
        </section>
        <section>
          <title>RTP/TCP</title>
          <para>This optional mode has been deprecated due to ambiguities in the interpretation of the respective RFCs. RTP/TCP protocol is defined in [RFC 4571] and [RFC 4572].</para>
        </section>
        <section>
          <title>RTP/RTSP/TCP</title>
          <para>The device should support media transfer using RTP/RTSP to traverse a firewall using an RTSP tunnel. This protocol shall conform to [RFC 2326] Section 10.12 (Embedded [Interleaved] Binary Data).</para>
        </section>
        <section xml:id="_Ref213038219">
          <title>RTP/RTSP/HTTP/TCP</title>
          <para>The data stream shall be sent via HTTP to traverse a firewall. A device shall support media transfer using RTP/RTSP/HTTP/TCP. If a device supports TLS, the data stream shall support transmission via HTTPS to traverse a firewall, and a device shall support media transfer using RTP/RTSP/HTTPS/TCP.</para>
          <para>This protocol shall conform to [RFC 2326] Section 10.12.</para>
          <para>This traversal method shall conform to [RTSP over HTTP]. Note that according to this specification all data sent from the client via POST must be base64 encoded.</para>
        </section>
        <section>
          <title>RTP/RTSP/TCP/WebSocket</title>
          <para>The device indicating support for RTSP over WebSocket, as explained in section 5.11 of the ONVIF Media2 Service Specification and section 5.5 of the ONVIF Replay Control Service Specification, shall support streaming media using WebSocket protocol according to this specification. The provided URI shall set the hierarchical part (hier_part) to absolute path (abs_path) [RFC 2396]. For example, if the WebSocket URI with network path is “ws://1.2.3.4/my-websocket-uri”, the provided URI shall be “ws:/my-websocket-uri”.</para>
          <para>For RTSP tunneling over WebSocket a device shall support RTP/RTSP/TCP interleaved binary data as defined in [RFC 2326] Section 10.12.</para>
          <para>WebSocket protocol implementation shall conform to [RFC 6455] - The WebSocket Protocol.</para>
          <para>The mechanism to be used for establishing a WebSocket connection between a client and server is explained in detail in Section 7.</para>
        </section>
      </section>
      <section xml:id="_Ref474396811">
        <title>Media Transport </title>
        <section>
          <title>RTP</title>
          <para>The Real-time Transport Protocol provides real-time transfer for media streams between two end points. The RTP protocol provides support for re-ordering, de-jittering and media synchronization.</para>
          <para>All media streams transferred by the RTP protocol shall conform to [RFC 3550], [RFC 3551], [RFC 3984], [RFC 7798], [RFC 3016] or [RFC 3640], and JPEG over RTP (see Section <xref linkend="_Toc214944378" />).</para>
          <figure>
            <title>RTP header</title>
            <mediaobject>
              <imageobject>
                <imagedata fileref="media/Streaming/rtpHeader.svg" contentwidth="160mm"/>
              </imageobject>
            </mediaobject>
          </figure>
          <para>An RTP header shall be filled up with following values.</para>
          <table>
            <title>RTP header value</title>
            <tgroup cols="3">
              <colspec colname="c1" colwidth="28*" />
              <colspec colname="c2" colwidth="38*" />
              <colspec colname="c3" colwidth="34*" />
              <thead>
                <row>
                  <entry>
                    <para>Header field</para>
                  </entry>
                  <entry>
                    <para>Value</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                </row>
              </thead>
              <tbody valign="top">
                <row>
                  <entry>
                    <para>Version (V): 2 bits</para>
                  </entry>
                  <entry>
                    <para>2</para>
                  </entry>
                  <entry />
                </row>
                <row>
                  <entry>
                    <para>Padding (P): 1 bit</para>
                  </entry>
                  <entry>
                    <para>0/1</para>
                  </entry>
                  <entry>
                    <para>If the payload includes padding octet, this should be set to “1”</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Extension (X): </para>
                    <para>1 bit</para>
                  </entry>
                  <entry>
                    <para>0/1</para>
                  </entry>
                  <entry>
                    <para>Depends on the use of extension of RTP header. The specification defines two scenarios where a RTP header extension could be used to transmit additional information:</para>
                    <para>1) “JPEG over RTP” (see Section <xref linkend="_Toc214944378" />).</para>
                    <para>2) Replay (see Section <xref linkend="_Ref279441431" />)</para>
                    <para>If the header extension is used the Extension bit shall be set. </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>CSRC count (CC): </para>
                    <para>4 bits</para>
                  </entry>
                  <entry>
                    <para>0</para>
                  </entry>
                  <entry />
                </row>
                <row>
                  <entry>
                    <para>Marker (M): </para>
                    <para>1 bit</para>
                  </entry>
                  <entry>
                    <para>0/1</para>
                  </entry>
                  <entry>
                    <para>The usage shall be conform to related RFCs (e.g. [RFC 3984] for H.264 Video) or to this standard e.g “JPEG over RTP” (see Section <xref linkend="_Toc214944378" />) or RTP streaming of metadata (see Section <xref linkend="_Ref213223702" />).</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Payload type (PT): </para>
                    <para>7 bits</para>
                  </entry>
                  <entry>
                    <para>See [RFC 3551] Section 6.</para>
                  </entry>
                  <entry />
                </row>
                <row>
                  <entry>
                    <para>Sequence Number: </para>
                    <para>16 bits</para>
                  </entry>
                  <entry />
                  <entry>
                    <para>The initial value of the “sequence number”      should be random (unpredictable) to make known-plaintext attacks on encryption more difficult.</para>
                    <para>This number increments by one for each RTP data packet sent</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>timestamp: </para>
                    <para>32 bits</para>
                  </entry>
                  <entry />
                  <entry>
                    <para>The initial value of the “timestamp” should be random (unpredictable) to make known-plaintext attacks on encryption more difficult.</para>
                    <para>See Section <xref linkend="_Toc208657714" /> for further details of Media Synchronization. </para>
                    <para>The usage of the timestamp is <phrase>dependent</phrase> on the codec.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>SSRC</para>
                    <para>32 bits</para>
                  </entry>
                  <entry />
                  <entry>
                    <para>The synchronization source for the data stream. This specification makes no restrictions on the use of this field.</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </table>
          <section xml:id="_Ref213223702">
            <title>RTP for Metadata stream</title>
            <para>Metadata streams are also transported by RTP. The usage of payload type, marker and timestamp for RTP header for the metadata stream is defined in the following way:</para>
            <itemizedlist>
              <listitem>
                <para>A dynamic payload type (96-127) shall be used for payload type which is assigned in the process of a RTSP session setup.</para>
              </listitem>
              <listitem>
                <para>The RTP marker bit shall be set to “1” when the XML document is closed. </para>
              </listitem>
              <listitem>
                <para>It is RECOMMENDED to use an RTP timestamp representing the creation time of the RTP packet with a RTP clock rate of 90000 Hz. Only UTC timestamps shall be used within the metadata stream. The synchronization of video and audio data streams is done using RTCP.</para>
              </listitem>
            </itemizedlist>
            <para>The Metadata payload is an XML document with root node <literal>tt:MetaDataStream</literal>. There is no limitation on the size of the XML document. If GZIP compression is used, the payload starts with a GZIP header according to RFC 1952 followed by the compressed data. A marker bit signals the end of the compressed data. When a synchronization point (see section “Synchronization Points” of the ONVIF Media Service Specification) is requested for the stream, the previous XML document shall be closed and a new one started. It is RECOMMENDED to start new XML documents after 1 second, at the longest. The RTP timestamp of the Metadata stream has no specific meaning. The Metadata stream multiplexes Metadata from different sources. This specification defines placeholders for the Scene Description of the Video Analytics, the PTZ Status of the PTZ controller and the Notifications of the Event Configuration. A device can select which of these parts should be multiplexed into the Metadata during the Media Configuration (see seciont “Metadata Configuration” of the ONVIF Media Service Specification). Each part can appear multiple times in arbitrary order within the document. A Metadata connection can be bi-directional using the backchannel mechanism (see Section <xref linkend="_Ref231788974" />). </para>
            <para>Metadata stream contains the following elements:</para>
            <itemizedlist>
              <listitem>
                <para>VideoAnalyticsStream</para>
              </listitem>
              <listitem>
                <para>PTZStream</para>
              </listitem>
              <listitem>
                <para>EventStream</para>
              </listitem>
            </itemizedlist>
            <para>The place-holders for the different metadata sources have the following XMLstructure:</para>
            <programlisting><![CDATA[<xs:complexType name="VideoAnalyticsStream">
  <xs:choice minOccurs="0" maxOccurs="unbounded">
    <xs:element name="Frame" type="tt:Frame"/>
    ...
  </xs:choice>
</xs:complexType>
<xs:complexType name="PTZStream">
  <xs:choice minOccurs="0" maxOccurs="unbounded">
    <xs:element name="PTZStatus" type="tt:PTZStatus"/>
    ...
  </xs:choice>
</xs:complexType>
<xs:complexType name="EventStream">
  <xs:choice minOccurs="0" maxOccurs="unbounded">
    <xs:element ref="wsnt:NotificationMessage"/>
    ...
  </xs:choice>
</xs:complexType>
]]></programlisting>
            <para>Note: For a PTZ supported device, the PTZStream in metadata provides the PTZ position information, whenever there is a change in the PTZ position, whereas PTZStatus defined inside VideoAnalyticsStream, provides PTZ position information at the time of generating scene description.</para>
            <para>The following is an example of a metadata XML document:</para>
            <programlisting><![CDATA[<?xml version="1.0" encoding="UTF-8"?>
  <tt:MetadataStream xmlns:tt="http://www.onvif.org/ver10/schema">
    <tt:VideoAnalytics>
      <tt:Frame UtcTime="2008-10-10T12:24:57.321">
        ...
      </tt:Frame>
      <tt:Frame UtcTime="2008-10-10T12:24:57.621">
        ...
      </tt:Frame>
    </tt:VideoAnalytics>
  </tt:MetadataStream>
  <?xml version="1.0" encoding="UTF-8"?>
    <tt:MetadataStream xmlns:tt="http://www.onvif.org/ver10/schema">
      <tt:Event>
        <wsnt:NotificationMessage>
          <wsnt:Message>
            <tt:Message UtcTime= "2008-10-10T12:24:57.628">
              ...
            </tt:Message>
          </wsnt:Message>
        </wsnt:NotificationMessage>
      </tt:Event>
    </tt:MetadataStream>
]]></programlisting>
          </section>
        </section>
        <section>
          <title>RTCP</title>
          <para>The RTP Control Protocol provides feedback on quality of service being provided by RTP and synchronization of different media streams. The RTCP protocol shall conform to [RFC 3550].  </para>
          <para>For a feedback request, [RFC 4585] and [RFC 5104] should be supported.</para>
          <figure>
            <title>RTCP sequence</title>
            <mediaobject>
              <imageobject>
                <imagedata fileref="media/Streaming/image3.svg" contentwidth="104.8mm" contentdepth="89.4mm" />
              </imageobject>
            </mediaobject>
          </figure>
          <section xml:id="_Toc208657714">
            <title>Media synchronization</title>
            <para>A client MAY receive audio and video streams simultaneously from more than one device. In this case, each stream uses a different clock (from data acquisition to packet receiving). RTCP Sender Reports (SR) are used to synchronize different media streams. RTCP SRs shall conform to [RFC 3550]. </para>
            <para>The RTCP Sender Report (SR) packet has fields for the RTP timestamp and for a wall clock timestamp (absolute date and time, 64bit NTP [Network Time Protocol]). See <xref linkend="_Ref213211787" />.</para>
            <para>A device shall support RTCP Sender Report for media synchronization. The client should use RTCP for the media synchronization. </para>
            <figure xml:id="_Ref213211787">
              <title>RTCP Sender Report</title>
              <mediaobject>
                <imageobject>
                  <imagedata fileref="media/Streaming/senderReport.svg" contentwidth="160mm"/>
                </imageobject>
              </mediaobject>
            </figure>
            <para>The wall clock should be common in the device and each timestamp value should be determined properly. The client can synchronize different media streams at the appropriate timing based on the RTP clock and wall clock timestamps (see <xref linkend="_Ref213211876" />).</para>
            <para>In case of multiple devices, the NTP timestamp should be common to all devices, and the NTP server should be required in the system <footnote xml:id="__FN1__"><para>The client can get information about “NTP server availability” from the devices by using the GetNTP command. Refer to Section 8.2.5</para></footnote>.</para>
            <figure xml:id="_Ref213211876">
              <title>Media Synchronization</title>
              <mediaobject>
                <imageobject>
                  <imagedata fileref="media/Streaming/image4a.svg" contentwidth="150mm" contentdepth="67.1mm" />
                </imageobject>
              </mediaobject>
            </figure>
          </section>
        </section>
      </section>
      <section xml:id="_Toc214944378">
        <title>Synchronization Point</title>
        <para>Synchronization points allow clients to decode and correctly use data after the synchronization point. A synchronization point MAY be requested by a client in case of decoder error (e.g. in consequence of packet loss) to enforce the device to add an I-Frame as soon as possible or to request the current ptz or event status.</para>
        <para>The WebService based methods require to support the Synchronization Point request as defined in the section “Synchronization Point” of the ONVIF Media Service Specification. </para>
        <para>In addition it is recommended to support the PLI messages as described in [RFC 4585] in order to allow receivers as defined in the ONVIF Receiver Service Specification to request a Synchronization Point. </para>
        <para>For H.264 and H.265 Video the SPS/PPS header shall be sent in-band if these have been changed during the transmission.</para>
      </section>
      <section xml:id="_Ref289166764">
        <title>JPEG over RTP</title>
        <section>
          <title>Overall packet structure</title>
          <para>The syntax for transmitting JPEG streams follows [RFC 2435]. The syntax does allow embedding additional data, beyond the limits of [RFC 2435], by using an optional RTP header extension, as specified below, with some of the RTP packets. This option, however, changes the exact semantics for frames which include such packets.</para>
          <para>The overall format of the JPEG RTP packet is shown in <xref linkend="_Ref213213069" />.</para>
          <figure xml:id="_Ref213213069">
            <title>RTP/JPEG packet structure (only the typical content  is listed for the extension payload)</title>
            <mediaobject>
              <imageobject>
                <imagedata fileref="media/Streaming/image4.svg" contentwidth="168.3mm" contentdepth="108.5mm" />
              </imageobject>
            </mediaobject></figure>
          <para>In order to distinguish an optional RTP header extension from possible other header extensions, the first 16 bits (the first two octets of the four-octet extension header) of an RTP shall have the value <literal>0xFFD8</literal> (JPEG SOI marker) for the initial packet and <literal>0xFFFF</literal> for other RTP packets within a frame.</para>
          <para>As required by [RFC 3550], the presence of the optional header extension shall be signalled via the X-bit of the RTP header. The extension length field within the header extension counts the number of 32-bit items following as extension payloads. For example, a zero-length field following the 32-bit extension header represents an empty header extension).</para>
          <para>The entropy-encoded scan data section MAY not be present in all RTP packets. A complete RTP/JPEG header however shall be present in the initial packet of every frame and all packets containing an entropy-encoded scan data section, otherwise it MAY be missing.</para>
          <para>The fragment offset field within the RTP/JPEG header, according to [RFC 2435], should be used as if no header extension would be present. Additionally, if a packet does not contain an entropy-encoded scan data segment, but contains a header extension the fragment offset field shall not be zero if any packets containing an entropy-encoded scan data section for the same frame have been transmitted. If the initial packet of a frame contains no header extension, according to this standard, its fragment offset field shall be zero, otherwise it should be zero. All packets including an RTP/JPEG header with a fragment offset of zero and a Q value between 128-255 shall include a quantization table header according to Section 3.1.8 of [RFC 2435], other packets shall NOT include this header.</para>
        </section>
        <section>
          <title>Logical decoding specification</title>
          <para>For the decoding specification, it is assumed that the original packet order within the RTP stream has been restored according to the RTP sequence numbering.</para>
          <para>If the initial packet of a frame contains no RTP header extension as specified above, decoders shall generate the complete scan header and perform the decoding as specified by [RFC 2435]. The scan data sections and payloads of any header extension conforming to this specification, up to and including the next RTP packet with its marker bit set, shall be concatenated as they occur within the stream ignoring their fragment offset values. </para>
          <para>Otherwise (at least an empty header extension as specified above is present in the initial packet of a frame), the following rules apply for each such frame:</para>
          <itemizedlist>
            <listitem>
              <para>If the initial packet of a frame does not contain an entropy-encoded scan data segment, but contains a header extension as specified above, then decoders shall concatenate its header extension payload with (possibly empty or not existing) header extension payload(s) conforming to this specification of the subsequent packets up to and including the first packet with the RTP marker bit set or containing an entropy-encoded scan data segment.</para>
            </listitem>
            <listitem>
              <para>The concatenated initial RTP header extension payload (sequence) shall be logically prepended with a JPEG SOI marker (0xFFD8). </para>
            </listitem>
            <listitem>
              <para>If the Q-value of the RTP/JPEG scan header within the initial packet of a frame is not zero, the quantization tables shall be pre-initialized according to the rules of [RFC 2435]. If Q is equal to zero the quantization tables shall be copied from the previous frame, allowing for DQT markers within this initial header extension payload (sequence) to override them. </para>
            </listitem>
            <listitem>
              <para>If this frame is the initial frame of a sequence, the Huffman tables shall be pre-initialized according to [RFC 2435]. The Huffman tables for all subsequent frames shall be copied from the previous frame, allowing the frames to be overridden by DHT markers within the initial header extension payload (sequence). </para>
            </listitem>
            <listitem>
              <para>If the initial RTP header extension payload (sequence) supplies no DRI marker, but the RTP/JPEG header of the initial packet of a frame contains an RTP/JPEG restart marker, a DRI marker corresponding to the rules of [RFC 2435] shall be appended to the initial header extension payload (sequence). Otherwise, if the initial RTP header extension (sequence) supplies a DRI marker, the marker shall take precedence over any other RTP/JPEG restart marker according to [RFC 2435] for the same frame. However, for compatibility with decoders conforming to [RFC 2435] only, encoders normally should use an RTP/JPEG restart marker with consistent values, if restart intervals are to be used.</para>
            </listitem>
            <listitem>
              <para>DRI markers shall NOT be derived from previous frames.</para>
            </listitem>
            <listitem>
              <para>If the initial RTP header extension payload (sequence) supplies no SOF marker, which otherwise takes precedence, a SOF marker shall be appended to it with the following values: </para>
              <itemizedlist>
                <listitem>
                  <para>If both the width and height field of the RTP/JPEG header are zero, the SOF marker of the previous frame shall be used. </para>
                </listitem>
                <listitem>
                  <para>Otherwise it shall be derived according to the rules of [RFC 2435].</para>
                </listitem>
              </itemizedlist>
              <para>However, as long as the (rounded up) image size fits within the range as specified in [RFC 2435], encoders should specify the image size within the RTP/JPEG header consistent with the values of an additional SOF header.</para>
            </listitem>
            <listitem>
              <para>If the initial header extension payload (sequence) supplies no SOS marker, a corresponding marker shall be derived according to [RFC 2435] and appended to it, otherwise the SOS marker in the extension takes precedence.</para>
              <para>An SOS marker shall NOT be derived from previous frames.</para>
              <para>If the SOS marker is present and not followed by entropy-encoded scan data within the extension, the marker shall be the final marker within the initial extension payload (sequence) of a frame. Necessary padding with 0xFF-octets shall NOT follow this marker but MAY precede it.</para>
            </listitem>
            <listitem>
              <para>The remaining entropy-encoded scan data and header extensions payloads shall be logically appended in the same order as they occur within the RTP stream up to the end of the frame as indicated by the RTP marker bit. A final EOI marker shall also be added if it is not yet present within the logical sequence for this frame,.</para>
              <para>For each frame, the resulting sequence up to and including the first (possibly added) EOI marker shall be a valid (possibly abbreviated) JPEG stream, resulting in one complete image from the decoding process for this frame. The meaning of any data after this first EOI marker for each frame is outside the scope of this specification.</para>
            </listitem>
          </itemizedlist>
          <para>Implementations should provide for each frame the complete JPEG headers. This holds especially for the width and height information as well as the quantization and Huffman tables. If such important information is not provided for each frame, both playback and multicast streaming may suffer from incomplete JPEG header information.</para>
        </section>
        <section>
          <title>Supported colour spaces and sampling factors</title>
          <para>A Transmitter should use only greyscale and YCbCr colour space. A Client shall support both greyscale and YcbCr.</para>
          <para>The sampling factors for YcbCr shall correspond to the values supported by [RFC 2435]. For example, a sampling factor of 4:2:0 (preferred) or 4:2:2.</para>
        </section>
        <section>
          <title>Pixel aspect ratio handling</title>
          <para>The pixel aspect ratio of JPEG files can be specified within the JFIF marker. If the pixel aspect ratio is different from the standard 1:1 and 1:2 ratio according to [RFC 2435], this marker should be transmitted in the initial header extension payload (sequence) of every frame to specify the (for interlaced material field-based) pixel aspect ratio.</para>
        </section>
        <section>
          <title>Interlaced handling</title>
          <para>Interlaced video is encoded as two independent fields and signalled as specified by [RFC 2435] within the RTP/JPEG header.</para>
          <para>Both fields shall use the same colour space, sampling factors and pixel aspect ratio.</para>
          <para>Interlaced encoding should NOT be used if the frame was originally scanned progressively.</para>
        </section>
      </section>
    </section>
    <section>
      <title>Media control protocol</title>
      <section>
        <title>Stream control</title>
        <para>The media stream is controlled using the protocol defined in the URI. The URI is returned in response to the GetStreamUri command defined in the ONVIF Media Service Specification.</para>
        <figure>
          <title>Stream Control</title>
          <mediaobject>
            <imageobject>
              <imagedata fileref="media/Streaming/image5a.svg" contentwidth="151mm" contentdepth="120.7mm" />
            </imageobject>
          </mediaobject>
        </figure>
      </section>
        <section>
          <title>RTSP</title>
          <section>
            <title>General</title>
          <para>All devices and clients shall support RTSP ([RFC 2326]) for session initiation and playback control. RTSP shall use TCP as its transport protocol, the default TCP port for RTSP traffic is 554. The Session Description Protocol (SDP) shall be used to provide media stream information and SDP shall conform to [RFC 4566].</para>
          <table>
            <title>RTSP methods.</title>
            <tgroup cols="4">
              <colspec colname="c1" colwidth="21*" />
              <colspec colname="c2" colwidth="10*" />
              <colspec colname="c3" colwidth="11*" />
              <colspec colname="c4" colwidth="58*" />
              <thead>
                <row>
                  <entry valign="middle">
                    <para>Method</para>
                  </entry>
                  <entry valign="middle">
                    <para>Direction</para>
                  </entry>
                  <entry valign="middle">
                    <para>SPEC<footnote xml:id="__FN2__"><para><superscript>X: Not supported, M: Mandatory, O: Optional</superscript></para></footnote></para>
                  </entry>
                  <entry>
                    <para>Description </para>
                  </entry>
                </row>
              </thead>
              <tbody valign="top">
                <row>
                  <entry valign="middle">
                    <para>OPTIONS</para>
                  </entry>
                  <entry valign="middle">
                    <para>R-&gt;T T-&gt;R</para>
                  </entry>
                  <entry valign="middle">
                    <para>M X</para>
                  </entry>
                  <entry>
                    <para>Required to get optional method capability and to allow different versions in the future.</para>
                  </entry>
                </row>
                <row>
                  <entry valign="middle">
                    <para>DESCRIBE</para>
                  </entry>
                  <entry valign="middle">
                    <para>R-&gt;T</para>
                  </entry>
                  <entry valign="middle">
                    <para>M</para>
                  </entry>
                  <entry>
                    <para>Required to retrieve media parameters within the designated profile.</para>
                  </entry>
                </row>
                <row>
                  <entry valign="middle">
                    <para>ANNOUNCE</para>
                  </entry>
                  <entry valign="middle">
                    <para>R-&gt;T T-&gt;R</para>
                  </entry>
                  <entry valign="middle">
                    <para>X</para>
                  </entry>
                  <entry />
                </row>
                <row>
                  <entry valign="middle">
                    <para>SETUP</para>
                  </entry>
                  <entry valign="middle">
                    <para>R-&gt;T</para>
                  </entry>
                  <entry valign="middle">
                    <para>M</para>
                  </entry>
                  <entry>
                    <para>Required to set media session　parameters.</para>
                  </entry>
                </row>
                <row>
                  <entry valign="middle">
                    <para>PLAY</para>
                  </entry>
                  <entry valign="middle">
                    <para>R-&gt;T</para>
                  </entry>
                  <entry valign="middle">
                    <para>M</para>
                  </entry>
                  <entry>
                    <para>Required to start media stream.</para>
                  </entry>
                </row>
                <row>
                  <entry valign="middle">
                    <para>PAUSE</para>
                  </entry>
                  <entry valign="middle">
                    <para>R-&gt;T</para>
                  </entry>
                  <entry valign="middle">
                    <para>Live: O</para>
                    <para>Replay: M</para>
                  </entry>
                  <entry>
                    <para>Required to temporarily stop media playback.</para>
                    <para>Handling multiple streams in a narrow bandwidth network, by suspending RTP stream, the traffic can be well controlled by reducing redundant data and congested network traffic can be avoided.</para>
                  </entry>
                </row>
                <row>
                  <entry valign="middle">
                    <para>TEARDOWN</para>
                  </entry>
                  <entry valign="middle">
                    <para>R-&gt;T</para>
                  </entry>
                  <entry valign="middle">
                    <para>M</para>
                  </entry>
                  <entry>
                    <para>Required to release a media session.</para>
                  </entry>
                </row>
                <row>
                  <entry valign="middle">
                    <para>GET_PARAMETER</para>
                  </entry>
                  <entry valign="middle">
                    <para>R-&gt;T T-&gt;R</para>
                  </entry>
                  <entry valign="middle">
                    <para>O</para>
                  </entry>
                  <entry />
                </row>
                <row>
                  <entry valign="middle">
                    <para>SET_PARAMETER</para>
                  </entry>
                  <entry valign="middle">
                    <para>R-&gt;T T-&gt;R</para>
                  </entry>
                  <entry valign="middle">
                    <para>O </para>
                    <para>O</para>
                  </entry>
                  <entry>
                    <para>An optional method to keep an RTSP session alive (R-&gt;T direction only).</para>
                  </entry>
                </row>
                <row>
                  <entry valign="middle">
                    <para>REDIRECT</para>
                  </entry>
                  <entry valign="middle">
                    <para>T-&gt;R</para>
                  </entry>
                  <entry valign="middle">
                    <para>X</para>
                  </entry>
                  <entry />
                </row>
                <row>
                  <entry valign="middle">
                    <para>RECORD</para>
                  </entry>
                  <entry valign="middle">
                    <para>R-&gt;T</para>
                  </entry>
                  <entry valign="middle">
                    <para>X</para>
                  </entry>
                  <entry valign="middle" />
                </row>
              </tbody>
            </tgroup>
          </table>
          <para>Devices shall support aggregate stream control, in which PLAY commands are sent to the control URI for the whole session. Devices may support non aggregate stream control, in which PLAY commands are sent separately to the stream control URIs in the media sections of the SDP file. Support for non aggregate stream control is signalled via the Media Streaming Capabilities.</para>
          </section>
            <section>
            <title>Timeout and keep-alive handling</title>
            <para>An RTSP client is required to keep the RTSP session alive and prevent it from
            session timeout (see [RFC 2326] Section 12.37). </para>
          <para>This specification recommends the following behavior of keeping RTSP sessions alive
            for both Unicast and Multicast streaming:</para>
          <itemizedlist>
            <listitem><para>In all RTSP SETUP responses, a server should include the Timeout value according to [RFC 2326]
                Section 12.37.</para></listitem>
            <listitem><para>A server shall interpret any RTSP request other than TEARDOWN as a keep-alive.</para></listitem>
            <listitem><para>Clients should use SET_PARAMETER as keep-alive method for the RTSP session.</para></listitem>
            <listitem><para>A server shall interpret any RTCP receiver report for a unicast stream as keep-alive for the
                RTSP session.</para></listitem>
            <listitem><para>If an RTSP session times out, a server should close related RTP streams as long as they are
                not shared with other active RTSP sessions.</para></listitem>
          </itemizedlist>
              <para>Note: for timeout handling see also the following sections of RFC 7826:</para>
              <itemizedlist>
                <listitem><para>Section 10.5. Showing Liveness</para></listitem>
                <listitem><para>Annex C.1.6.2. RTSP Session Keep-Alive</para></listitem>
              </itemizedlist>
            <figure>
              <title>Keep Alive</title>
              <mediaobject>
                <imageobject>
                  <imagedata fileref="media/Streaming/image5.svg" contentwidth="152.4mm" />
                </imageobject>
              </mediaobject>
            </figure>
          </section>
          <section>
            <title>RTSP audio and video synchronization</title>
            <para>In order that clients may immediately begin synchronizing video and audio streams, and computing absolute UTC timestamps for incoming packets for recording purposes, a transmitter should include the following header fields in the RTSP PLAY response:</para>
            <itemizedlist>
              <listitem>
                <para>Range ([RFC 2326] section 12.29). This SHALL include a start time in clock units ([RFC 2326] section 3.7), <emphasis>not</emphasis> SMPTE or NPT units.</para>
              </listitem>
              <listitem>
                <para>RTP-Info ([RFC 2326] section 12.33). This SHALL include an rtptime value which corresponds to the start time specified in the Range header.</para>
              </listitem>
            </itemizedlist>
            <para>Example:</para>
            <programlisting>client-&gt;server:   PLAY rtsp://example.com/onvif_camera/video RTSP/1.0
                  Cseq: 4
                  Range: npt=now-
                  Session: 12345678

server-&gt;client:   RTSP/1.0 200 OK
                  Cseq: 4
                  Session: 12345678
                  Range: clock=20100217T143720.257Z-
                  RTP-Info: url=rtsp://example.com/onvif_camera/video; seq=1234;rtptime=3450012</programlisting>
          </section>
          <section>
            <title>RTSP session for a metadata stream</title>
            <para>In the case of a metadata stream, the SDP description “application” shall be used in the DESCRIBE response for media type and one of these encoding a names shall be used</para>
            <itemizedlist>
              <listitem>
                <para>“vnd.onvif.metadata” for uncompressed</para>
              </listitem>
              <listitem>
                <para>“vnd.onvif.metadata+gzip” for GZIP compressed</para>
              </listitem>
              <listitem>
                <para>"vnd.onvif.metadata.exi.ext" for EXI using compression parameters that are sent in-band</para>
              </listitem>
            </itemizedlist>
            <para>Example RTSP DESCRIBE message exchange between an RTSP Server (server) and an RTSP client (client):</para>
            <programlisting><![CDATA[
client->server:   DESCRIBE rtsp://example.com/onvif_camera RTSP/1.0
                  Cseq: 1
                 
server->client:   RTSP/1.0 200 OK
                  Cseq: 1
                  Content-Type: application/sdp
                  Content-Length: XXX
                  v=0
                  o=- 2890844256 2890842807 IN IP4 172.16.2.93
                  s=RTSP Session
                  m=audio 0 RTP/AVP 0
                  a=control:rtsp://example.com/onvif_camera /audio
                  m=video 0 RTP/AVP 26
                  a=control:rtsp://example.com/onvif_camera /video
                  m=application 0 RTP/AVP 107
                  a=control:rtsp://example.com/onvif_camera/metadata
                  a=recvonly
                  a=rtpmap:107 vnd.onvif.metadata/90000
]]></programlisting>
          </section>
          <section>
            <title>Multicast streaming</title>
            <para>A device shall include a valid multicast address in the "c=" field of a DESCRIBE response according to RFC 4566.</para>
            <para>Remark: the optional dynamic multicast address assignment exception described in appendix C.1.7 of RFC 2326 allowing 0.0.0.0 addresses does not apply.</para>
            <para>Chapter 10.7 TEARDOWN of [RFC 2326] states that a device shall stop the stream delivery for the given URI on tear down. This needs to be clarified in case of multicast: for a multicast stream the device shall stop sending packets for a multicast configuration when no more RTSP sessions are using the same multicast configuration nor its AutoStart flag has been set.</para>
          </section>
          <section>
            <title>RTSP message example</title>
            <para>This example shows the message transfer between an RTSP client (client) and an RTSP server (server). The client requests one audio and one video stream from the device. The Stream Uri “rtsp://example.com/onvif_camera” can be retrieved using the GetStreamUri command. Refer to Section „Stream URI“ of the ONVIF Media Service Specification. </para>
            <programlisting><![CDATA[Client->server:    	DESCRIBE rtsp://example.com/onvif_camera RTSP/1.0
Cseq: 1
server->client:     RTSP/1.0 200 OK
                    Cseq: 1
                    Content-Type: application/sdp
                    Content-Length: XXX
                    v=0
                    o=- 2890844256 2890842807 IN IP4 172.16.2.93
                    s=RTSP Session
                    m=audio 0 RTP/AVP 0
                    a=control:rtsp://example.com/onvif_camera/audio
                    m=video 0 RTP/AVP 26
                    a=control:rtsp://example.com/onvif_camera/video

client->server:     SETUP rtsp://example.com/onvif_camera/audio RTSP/1.0
                    Cseq: 2
                    Transport: RTP/AVP;unicast;client_port=8002-8003

server->client:     RTSP/1.0 200 OK
                    Cseq: 2
                    Transport: RTP/AVP;unicast;client_port=8002-8003;
                    server_port=9004-9005
                    Session: 12345678; timeout=60
                    
client->server:     SETUP rtsp://example.com/onvif_camera/video RTSP/1.0
                    Cseq: 3
                    Transport: RTP/AVP;unicast;client_port=8004-8005
                    Session: 12345678
                    
server->client:     RTSP/1.0 200 OK
                    Cseq: 3
                    Transport: RTP/AVP;unicast;client_port=8004-8005;
                    server_port=9006-9007
                    Session: 12345678; timeout=60

client->server:     PLAY rtsp://example.com/onvif_camera RTSP/1.0
                    Cseq: 4
                    Range: npt=now-
                    Session: 12345678

server->client:     RTSP/1.0 200 OK
                    Cseq: 4
                    Session: 12345678
                    RTP-Info: url=rtsp://example.com/onvif_camera/video; seq=1234;rtptime=3450012, url=rtsp://example.com/onvif_camera/audio;
                    seq=22434;rtptime=1234566

client->server:     TEARDOWN rtsp://example.com/onvif_camera RTSP/1.0
                    Cseq: 5
                    Session: 12345678

server->client:     RTSP/1.0 200 OK
                    Cseq: 5
                    Session: 12345678
]]></programlisting>
          </section>
        </section>
        <section>
          <title>RTSP over HTTP</title>
          <para>The RTSP over HTTP/HTTPS shall be supported in order to traverse a firewall. See Section <xref linkend="_Ref213038219" /> RTP/RTSP/HTTP/TCP.</para>
        </section>
      </section>
    <section xml:id="_Ref231788974">
      <title>Back channel connection</title>
      <para>This section describes how a bidirectional connection can be established between a client and a server. The backchannel connection handling is done using RTSP [RFC 2326]. Therefore a mechanism is introduced which indicates that a client wants to establish a backchannel connection. RTSP provides feature-tags to deal with such functionality additions.  </para>
      <para>A device that supports bi-directional connections (e.g audio or metadata connections) shall support the introduced RTSP extensions.</para>
      <section xml:id="_Toc245780508">
        <title>RTSP Require tag </title>
        <para>The RTSP standard [RFC 2326] can be extended by using additional headers objects. For that purpose a Require tag is introduced to handle special functionality additions (see [RFC 2326], 1.5 Extending Rtsp and 12.32 Require). </para>
        <para>The Require-tag is used to determine the support of this feature. This header shall be included in any request where the server is required to understand that feature to correctly perform the request. </para>
        <para>A device that supports backchannel and signals Audio output support via the AudioOutputs capability shall understand the backchannel tag:</para>
        <itemizedlist>
          <listitem>
            <programlisting><![CDATA[www.onvif.org/ver20/backchannel
]]></programlisting>
          </listitem>
        </itemizedlist>
        <para>An RTSP client that wants to built up an RTSP connection with a data backchannel shall include the Require header in its requests.</para>
      </section>
      <section>
        <title>Connection setup for a bi- directional connection</title>
        <para>A client shall include the feature tag in it’s DESCRIBE request to indicate that a bidirectional data connection shall be established.</para>
        <para>A server that understands this Require tag shall include an additional media stream in its SDP file as configured in its Media Profile. </para>
        <para>An RTSP server that does not understand the backchannel feature tag or does not support bidirectional data connections shall respond with an error code <emphasis>551 Option not supported</emphasis> according to the RTSP standard. The client can then try to establish an RTSP connection without backchannel.</para>
        <para>A SDP file is used to describe the session. To indicated the direction of the media data the server shall include the a=sendonly in each media section representing media being sent from the client to the server and a=recvonly attributes in each media section representing media being sent from the server to the client.</para>
        <para>The server shall list all supported decoding codecs as own media section and the client chooses which one is used. The payload type and the encoded bitstream shall be matched with one of the a=rtpmap fields provided by the server so that the server can properly determine the audio decoder.</para>
        <section>
          <title>Describe example for a server without backchannel support:</title>
          <programlisting><![CDATA[Client – Server:		DESCRIBE rtsp://192.168.0.1 RTSP/1.0
Cseq: 1
User-Agent: ONVIF Rtsp client
Accept: application/sdp
Require:www.onvif.org/ver20/backchannel
Server – Client:    RTSP/1.0 551 Option not supported
                    Cseq: 1
                    Unsupported:www.onvif.org/ver20/backchannel
]]></programlisting>
        </section>
        <section>
          <title>Describe example for a server with Onvif backchannel support:</title>
          <programlisting><![CDATA[Client – Server:		DESCRIBE rtsp://192.168.0.1 RTSP/1.0
Cseq: 1
User-Agent: ONVIF Rtsp client
Accept: application/sdp
Require:www.onvif.org/ver20/backchannel
Server – Client:    RTSP/1.0 200 OK
                    Cseq: 1
                    Content-Type: application/sdp
                    Content-Length: xxx
                    v=0
                    o= 2890842807 IN IP4 192.168.0.1
                    s=RTSP Session with audiobackchannel
                    m=video 0 RTP/AVP 26
                    a=control:rtsp://192.168.0.1/video
                    a=recvonly
                    m=audio 0 RTP/AVP 0
                    a=control:rtsp://192.168.0.1/audio
                    a=recvonly
                    m=audio 0 RTP/AVP 0
                    a=control:rtsp://192.168.0.1/audioback
                    a=rtpmap:0 PCMU/8000
                    a=sendonly
]]></programlisting>
          <para>This SDP file completely describes the RTSP session. The Server gives the client its control URLs to setup the streams. </para>
          <para>In the next step the client can setup the sessions:</para>
          <programlisting><![CDATA[
Client – Server:	  SETUP rtsp://192.168.0.1/video RTSP/1.0
                  Cseq: 2
                  Transport: RTP/AVP;unicast;client_port=4588-4589
                  
Server – Client:  RTSP/1.0 200 OK
                  Cseq: 2
                  Session: 123124;timeout=60
                  Transport:RTP/AVP;unicast;client_port=4588-4589; server_port=6256-6257
                  
Client – Server:  SETUP rtsp://192.168.0.1/audio RTSP/1.0
                  Cseq: 3
                  Session: 123124
                  Transport: RTP/AVP;unicast;client_port=4578-4579
                  
Server – Client:  RTSP/1.0 200 OK
                  Cseq: 3
                  Session: 123124;timeout=60
                  Transport:RTP/AVP;unicast;client_port=4578-4579; server_port=6276-6277
                  
Client – Server:  SETUP rtsp://192.168.0.1/audioback RTSP/1.0
                  Cseq: 4
                  Session: 123124
                  Transport: RTP/AVP;unicast;client_port=6296-6297
                  Require:www.onvif.org/ver20/backchannel
                  
Server – Client:  RTSP/1.0 200 OK
                  Cseq: 4
                  Session: 123124;timeout=60
                  Transport:RTP/AVP;unicast;client_port=6296-6297; server_port=2346-2347
]]></programlisting>
          <para>The third setup request establishes the audio backchannel connection. </para>
          <para>In the next step the client starts the session by sending a PLAY request.</para>
          <programlisting><![CDATA[Client – Server: 		PLAY rtsp://192.168.0.1 RTSP/1.0
Cseq: 5
Session: 123124
Require:www.onvif.org/ver20/backchannel
Server – Client:  		RTSP/1.0 200 OK
Cseq: 5
Session: 123124;timeout=60
]]></programlisting>
          <para>After receiving the OK response to the PLAY request the client can start sending audio data to the server. It shall not start sending data to the server before it has received the response. </para>
          <para>The Require-header indicates that a special interpretation of the PLAY command is necessary. The command covers both starting of the video and audio stream from NVT to the client and starting the audio connection from client to server.</para>
          <para>To terminate the session the client sends a TEARDOWN request.</para>
          <programlisting><![CDATA[Client – NVT: 	TEARDOWN rtsp://192.168.0.1 RTSP/1.0
Cseq: 6
Session: 123124
Require:www.onvif.org/ver20/backchannel
NVT – Client: 	RTSP/1.0 200 OK
Cseq: 6
Session: 123124
]]></programlisting>
        </section>
        <section>
          <title>Describe example in case of backchannel support with multiple decoding capability</title>
          <para>If a device supports multiple audio decoders as backchannel, it can signal such capability by listing multiple a=rtpmap fields illustrated as follows.</para>
          <programlisting><![CDATA[Client – Server:		DESCRIBE rtsp://192.168.0.1 RTSP/1.0
Cseq: 1
User-Agent: ONVIF Rtsp client
Accept: application/sdp
Require: www.onvif.org/ver20/backchannel
Server – Client: 		RTSP/1.0 200 OK
Cseq: 1
Content-Type: application/sdp
Content-Length: xxx
v=0
o= 2890842807 IN IP4 192.168.0.1
s=RTSP Session with audiobackchannel
m=video 0 RTP/AVP 26
a=control:rtsp://192.168.0.1/video
a=recvonly
m=audio 0 RTP/AVP 0
a=control:rtsp://192.168.0.1/audio
a=recvonly
m=audio 0 RTP/AVP 0 97 98 99 100
a=control:rtsp://192.168.0.1/audioback
a=rtpmap:0 PCMU/8000
a=rtpmap:97 G726-16/8000
a=rtpmap:98 G726-24/8000
a=rtpmap:99 G726-32/8000
a=rtpmap:100 G726-40/8000
a=sendonly
]]></programlisting>
        </section>
      </section>
      <section>
        <title>Multicast streaming</title>
        <para>If the client intents to send its data in multicast it uses the transport parameter in the SETUP request to tell the server the multicast address and port.</para>
        <para>Note that multicast streaming for Audio Backchannel is outside of the scope of this specification.</para>
        <section>
          <title>Example: Multicast Setup</title>
          <programlisting><![CDATA[Client – Server:		SETUP rtsp://192.168.0.1/audioback RTSP/1.0
Cseq: 4
Session: 123124
Transport:RTP/AVP;multicast;destination=224.2.1.1;port=60000-60001;ttl=128
Require:www.onvif.org/ver20/backchannel
Server – Client: 		RTSP/1.0 200 OK
Cseq: 4
Session: 123124;timeout=60
Transport:RTP/AVP;multicast;destination=224.2.1.1;port=60000-60001;ttl=128;mode=”PLAY”
]]></programlisting>
        </section>
      </section>
    </section>
    <section>
      <title>Multitrack streaming</title>
      <para>This section describes how to establish an RTSP stream containing mutiple video tracks between a client and a server. The connection handling refers to the Session Description Protocol (SDP) Grouping Framework [RFC 5888].</para>
      <section>
        <title>Group Attribute</title>
        <para>The session-level attribute "group" tdifferent media streams together.  Its format in SDP is described by the following ABNF:</para>
        <para>           group-attribute     = "a=group:" semantics</para>
        <para>                                          *(SP identification-tag)</para>
        <para>           semantics           =  "LS" / "FID" / semantics-extension</para>
        <para>           semantics-extension = token; token is defined in [RFC 4566]</para>
        <para>This section defines one standard semantics named llp synchronization (LS). Note, that audio video synchronization is out of scope of this section, but theis reused for multitrack streaming. </para>
      </section>
      <section>
        <title>Media Stream Identification Attribute</title>
        <para>The media attribute "media stream identification" is defined in this section, which is used to identify media streams within a session description.  Its format in SDP [RFC 4566] is described by the following ABNF:</para>
        <para>            mid-attribute      = "a=mid:" identification-tag</para>
        <para>            identification-tag = token; token is defined in [RFC 4566]</para>
        <para>The identification-tag should be unique within an SDP session description.</para>
      </section>
      <section>
        <title>Extension Attribute</title>
        <para>The SDP returned by the RTSP describes command shall include for each video stream a profile reference pointing to an exsiting media profile. It allows clients to map tracks to profiles for retrieve additional stitching information.</para>
        <para>The tag shall use the following format:</para>
        <para> 	a=x-onvif-profile:&lt;ProfileReference&gt;</para>
      </section>
      <section>
        <title>Example</title>
        <para>This section provides as example a camera with three sensors. For this example, the SDP information sent to client uses the Real Time Streaming Protocol (RTSP).</para>
        <para>When the client sends the describle command to server, the server generates the response information and the track to be sent in one session will be chosen. According to [RFC 5888], the fields “group” and “mid” are provided in the sdp information. The attribute “group” represents that the following “mid” stream can be sent in one session. To clearly notify the client which URL uses for setup, we use the attribute “control” with absolute path.  </para>
        <programlisting><![CDATA[Client – Server:		DESCRIBE rtsp://192.168.0.1 RTSP/1.0
Cseq: 1
User-Agent: ONVIF Rtsp client
Accept: application/sdp
Server – Client:  RTSP/1.0 200 OK
                  Cseq: 1
                  Content-Type: application/sdp
                  Content-Length: xxx
                  v=0
                  o=- 2890844256 2890842807 IN IP4 192.168.0.1
                  s=RTSP Session
                  a=group: LS 1 2 3
                  m=video 0 RTP/AVP 97
                  a=control:rtsp://192.168.0.1/video/trackID=1
                  a=ssrc:1234
                  a=mid:1
                  a=x-onvif-profile:ProfileToken1
                  m=video 0 RTP/AVP 98
                  a=control:rtsp://192.168.0.1/video/trackID=2
                  a=ssrc:2345
                  a=mid:2
                  a=x-onvif-profile:ProfileToken2
                  m=video 0 RTP/AVP 99
                  a=control:rtsp://192.168.0.1/video/trackID=3
                  a=mid:3
                  a=ssrc:5678
                  a=x-onvif-profile:ProfileToken3
]]></programlisting>
      </section>
    </section>
    <section>
      <title>Error handling</title>
      <para>RTSP and HTTP protocol errors are classified into different categories (for example, status codes 1xx, 2xx, 3xx, 4xx and 5xx respectively). The device and the client shall support and handle these status codes. For RTSP status code definitions refer to [RFC 2326], Section 11.0. For HTTP status code definitions refer HTTP/1.1 [RFC 2616],<emphasis role="bold"></emphasis>Section 10.0.</para>
    </section>
  </chapter>
  <chapter xml:id="_Ref279441431">
    <title>Playback</title>
    <section>
      <title>RTSP usage</title>
      <para>The replay protocol is based on RTSP [RFC 2326]. However because RTSP does not directly support many of the features required by CCTV applications, this standard defines several extensions to the protocol; these are detailed below.</para>
      <para>This standard makes the following stipulations on the usage of RTSP:</para>
      <orderedlist>
        <listitem>
          <para>RTP/RTSP/HTTP/TCP shall be supported by the server. This is the same transport protocol as a device that implements media streaming through the media service shall support, and the same requirements shall apply to replay streaming.</para>
        </listitem>
        <listitem>
          <para>The server shall support the unicast RTP/UDP transport for streaming.</para>
        </listitem>
        <listitem>
          <para>Clients should use a TCP-based transport for replay, in order to achieve reliable delivery of media packets.</para>
        </listitem>
        <listitem>
          <para>The server MAY elect not to send RTCP packets during replay. In typical usage RTCP packets are not required, because usually a reliable transport will be used, and because absolute time information is sent within the stream, making the timing information in RTCP sender reports redundant.</para>
        </listitem>
      </orderedlist>
    </section>
    <section>
      <title>RTSP describe</title>
      <para>The SDP returned by the RTSP describe command shall include the TrackReference for each track of the recording to allow a client to map the tracks presented in the SDP to tracks of the recording. The tag shall use the following format:</para>
      <para> 	a:x-onvif-track:&lt;TrackReference&gt;</para>
      <para>For example:</para>
      <programlisting>
NVS – NVT:  DESCRIBE rtsp://192.168.0.1 RTSP/1.0
            Cseq: 1
            User-Agent: ONVIF Rtsp client
            Accept: application/sdp
            
NVT – NVS:  RTSP/1.0 200 OK
            Cseq: 1
            Content-Type: application/sdp
            Content-Length: xxx
            v=0
            o= 2890842807 IN IP4 192.168.0.1
                     m=video 0 RTP/AVP 26
                      a=control:rtsp://192.168.0.1/video
            a=x-onvif-track:VIDEO001
            m=audio 0 RTP/AVP 98
            a=control:rtsp://192.168.0.1/audio
            a=x-onvif-track:AUDIO001
        </programlisting>
    </section>
    <section>
      <title>RTP header extension</title>
      <para>In order to allow clients to report a stable and accurate timestamp for each frame played back regardless of the direction of playback, it is necessary to associate an absolute timestamp with each packet, or each group of packets with the same RTP timestamp (e.g. a video frame). This is achieved using an RTP header extension containing an NTP timestamp and some additional information also useful for replay.</para>
      <para>The replay mechanism uses the extension ID 0xABAC for the replay extension.</para>
      <para>Below shows the general form of an RTP packet containing this extension:</para>
      <table>
        <title>RTP packet layout</title>
        <tgroup cols="12">
          <colspec colname="c1" colwidth="3*" />
          <colspec colname="c2" colwidth="3*" />
          <colspec colname="c3" colwidth="1*" />
          <colspec colname="c4" colwidth="3*" />
          <colspec colname="c5" colwidth="3*" />
          <colspec colname="c6" colwidth="4*" />
          <colspec colname="c7" colwidth="9*" />
          <colspec colname="c8" colwidth="1*" />
          <colspec colname="c9" colwidth="4*" />
          <colspec colname="c10" colwidth="21*" />
          <colspec colname="c11" colwidth="1*" />
          <colspec colname="c12" colwidth="50*" />
          <thead>
            <row>
              <entry namest="c1" nameend="c3" align="center">
                <para>V=2</para>
              </entry>
              <entry align="center">
                <para>P</para>
              </entry>
              <entry namest="c5" nameend="c6" align="center">
                <para>X=1</para>
              </entry>
              <entry namest="c7" nameend="c8" align="center">
                <para>CC</para>
              </entry>
              <entry align="center">
                <para>M</para>
              </entry>
              <entry namest="c10" nameend="c11" align="center">
                <para>PT</para>
              </entry>
              <entry align="center">
                <para>sequence number</para>
              </entry>
            </row>
          </thead>
          <tbody valign="top">
            <row>
              <entry namest="c1" nameend="c12" align="center">
                <para>timestamp</para>
              </entry>
            </row>
            <row>
              <entry namest="c1" nameend="c12" align="center">
                <para>synchronization source (SSRC) identifier</para>
              </entry>
            </row>
            <row>
              <entry namest="c1" nameend="c11" align="center">
                <para>0xABAC</para>
              </entry>
              <entry align="center">
                <para>length=3</para>
              </entry>
            </row>
            <row>
              <entry namest="c1" nameend="c12" align="center">
                <para>NTP timestamp…</para>
              </entry>
            </row>
            <row>
              <entry namest="c1" nameend="c12" align="center">
                <para>...NTP timestamp</para>
              </entry>
            </row>
            <row>
              <entry align="center">
                <para>C</para>
              </entry>
              <entry align="center">
                <para>E</para>
              </entry>
              <entry namest="c3" nameend="c4" align="center">
                <para>D</para>
              </entry>
              <entry align="center">
                <para>T</para>
              </entry>
              <entry namest="c6" nameend="c7" align="center">
                <para>mbz</para>
              </entry>
              <entry namest="c8" nameend="c10" align="center">
                <para>Cseq</para>
              </entry>
              <entry namest="c11" nameend="c12" align="center">
                <para>padding</para>
              </entry>
            </row>
            <row>
              <entry namest="c1" nameend="c12" align="center">
                <para>payload…</para>
              </entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      <para>The fields of this extension are as follows:</para>
      <itemizedlist>
        <listitem>
          <para>NTP timestamp. An NTP [RFC 1305] timestamp indicating the absolute UTC time associated with the access unit.</para>
        </listitem>
        <listitem>
          <para>C: 1 bit. Indicates that this access unit is a synchronization point or “clean point”, e.g. the start of an intra-coded frame in the case of video streams.</para>
        </listitem>
        <listitem>
          <para>E: 1 bit. Indicates the end of a contiguous section of recording. The last access unit in each track before a recording gap, or at the end of available footage, shall have this bit set. When replaying in reverse, the E flag shall be set on the last frame at the end of the contiguous section of recording.</para>
        </listitem>
        <listitem>
          <para>D: 1 bit. Indicates that this access unit follows a discontinuity in transmission. It is primarily used during reverse replay; the first packet of each GOP has the D bit set since it does not chronologically follow the previous packet in the data stream (see section <xref linkend="_Ref229292321" />).</para>
          <itemizedlist>
            <listitem>
              <para>T: 1 bit. Indicates that this is the terminal frame on playback of a track. A device should signal this flag in both forward and reverse playback whenever no more data is available for a track.</para>
            </listitem>
          </itemizedlist>
        </listitem>
        <listitem>
          <para>mbz: This field is reserved for future use and must be zero.</para>
        </listitem>
        <listitem>
          <para>Cseq: 1 byte. This is the low-order byte of the Cseq value used in the RTSP PLAY command that was used to initiate transmission. When a client sends multiple, consecutive PLAY commands, this value may be used to determine where the data from each new PLAY command begins.</para>
        </listitem>
      </itemizedlist>
      <para>The replay header extension shall be present in the first packet of every access unit (e.g. video frame).</para>
      <section>
        <title>NTP Timestamps</title>
        <para>The NTP timestamps in the RTP extension header shall correspond to the wallclock time as measured at the original frame grabber before encoding of the stream.</para>
        <para>For forward playback of I and P frames the NTP timestamps in the RTP extension header shall increase monotonically over successive packets within a single RTP stream.</para>
      </section>
      <section>
        <title>Compatibility with the JPEG header extension</title>
        <para>The replay header extension may co-exist with the header extension used by the JPEG RTP profile; this is necessary to allow replay of JPEG streams that use this extension. The JPEG extension is simply appended to the replay extension; its presence is indicated by an RTP header extension length field with a value greater than 3, and by the extension start codes of 0xFFD8 or 0xFFFF at the start of the fourth word of the extension content.</para>
        <para>The following illustrates a JPEG packet that uses both extensions:</para>
        <table>
          <title>RTP packet with JPEG header layout</title>
          <tgroup cols="11">
            <colspec colname="c1" colwidth="3*" />
            <colspec colname="c2" colwidth="3*" />
            <colspec colname="c3" colwidth="1*" />
            <colspec colname="c4" colwidth="3*" />
            <colspec colname="c5" colwidth="6*" />
            <colspec colname="c6" colwidth="9*" />
            <colspec colname="c7" colwidth="1*" />
            <colspec colname="c8" colwidth="4*" />
            <colspec colname="c9" colwidth="21*" />
            <colspec colname="c10" colwidth="1*" />
            <colspec colname="c11" colwidth="50*" />
            <thead>
              <row>
                <entry namest="c1" nameend="c3" align="center">
                  <para>V=2</para>
                </entry>
                <entry align="center">
                  <para>P</para>
                </entry>
                <entry align="center">
                  <para>X=1</para>
                </entry>
                <entry namest="c6" nameend="c7" align="center">
                  <para>CC</para>
                </entry>
                <entry align="center">
                  <para>M</para>
                </entry>
                <entry namest="c9" nameend="c10" align="center">
                  <para>PT</para>
                </entry>
                <entry align="center">
                  <para>sequence number</para>
                </entry>
              </row>
            </thead>
            <tbody valign="top">
              <row>
                <entry namest="c1" nameend="c11" align="center">
                  <para>timestamp</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c11" align="center">
                  <para>synchronization source (SSRC) identifier</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c10" align="center">
                  <para>0xABAC</para>
                </entry>
                <entry align="center">
                  <para>length=N+4</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c11" align="center">
                  <para>NTP timestamp…</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c11" align="center">
                  <para>...NTP timestamp</para>
                </entry>
              </row>
              <row>
                <entry align="center">
                  <para>C</para>
                </entry>
                <entry align="center">
                  <para>E</para>
                </entry>
                <entry namest="c3" nameend="c4" align="center">
                  <para>D</para>
                </entry>
                <entry namest="c5" nameend="c6" align="center">
                  <para>mbz</para>
                </entry>
                <entry namest="c7" nameend="c9" align="center">
                  <para>Cseq</para>
                </entry>
                <entry namest="c10" nameend="c11" align="center">
                  <para>padding</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c9" align="center">
                  <para>0xFFD8</para>
                </entry>
                <entry namest="c10" nameend="c11" align="center">
                  <para>jpeglength=N</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c11" align="center">
                  <para>extension payload: sequence of additional JPEG marker segments padded with 0xFF to the total extension length</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c11" align="center">
                  <para>payload…</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </section>
    </section>
    <section>
      <title>RTSP Feature Tag</title>
      <para>The Replay Service uses the “onvif-replay” feature tag to indicate that it supports the RTSP extensions described in this standard. This allows clients to query the server’s support for these extensions using the Require header as described in [RFC 2326] section <xref linkend="_Toc245780508" />	.</para>
      <para>Example:</para>
      <programlisting>
C-&gt;S:   SETUP rtsp://server.com/foo/bar/baz.rm RTSP/1.0
           Cseq: 302
           Require: onvif-replay
S-&gt;C:   RTSP/1.0 551 Option not supported
           Cseq: 302
           Unsupported: onvif-replay
        </programlisting>
      <para>The Replay Server shall accept a SETUP and PLAY command that includes a Require header containing the onvif-replay feature tag.</para>
    </section>
    <section>
      <title>Initiating Playback</title>
      <para>Playback is initiated by means of the RTSP PLAY method. For example:</para>
      <programlisting>
PLAY rtsp://192.168.0.1/path/to/recording RTSP/1.0
Cseq: 123
Session: 12345678
Require: onvif-replay
Range: clock=20090615T114900.440Z-
Rate-Control: no
        </programlisting>
      <para>The ReversePlayback capability defined in the ONVIF Replay Control Service Specification signals if a device supports reverse playback. Reverse playback is indicated using the Scale header field with a negative value. For example to play in reverse without no data loss a value of –1.0 would be used.</para>
      <programlisting>
PLAY rtsp://192.168.0.1/path/to/recording RTSP/1.0
Cseq: 123
Session: 12345678
Require: onvif-replay
Range: clock=20090615T114900.440Z-
Rate-Control: no
Scale: -1.0
        </programlisting>
      <para>If a device supports reverse playback it shall accept a Scale header with a value of –1.0. A device MAY accept other values for the Scale parameter. Unless the Rate-Control header is set to “no” (see below), the Scale parameter is used in the manner described in [RFC 2326]. If Rate-Control is set to “no”, the Scale parameter, if it is present, shall be either 1.0 or –1.0, to indicate forward or reverse playback respectively. If it is not present, forward playback is assumed.</para>
      <section>
        <title>Range header field</title>
        <para>A device shall support the Range field expressed using absolute times as defined by [RFC 2326]. Absolute times are expressed using the utc-range from [RFC 2326].</para>
        <para>Either open or closed ranges may be used. In the case of a closed range, the range is increasing (end time later than start time) for forward playback and decreasing for reverse playback. The direction of the range shall correspond to the value of the Scale header.</para>
        <para>In all cases, the first point of the range indicates the starting point for replay.</para>
        <para>The time itsel shall be given as </para>
        <programlisting>
utc-range = "clock" ["=" utc-range-spec] 
utc-range-spec = ( utc-time "-" [ utc-time ] ) / ( "-" utc-time ) 
utc-time = utc-date "T" utc-clock "Z" 
utc-date = 8DIGIT 
utc-clock = 6DIGIT [ "." 1*9DIGIT ]
        </programlisting>
        <para>as defined in [RFC2326]. </para>
        <para>Examples:</para>
        <programlisting>
PLAY rtsp://192.168.0.1/path/to/recording RTSP/1.0
Cseq: 123
Session: 12345678
Require: onvif-replay
Range: clock=20090615T114900.440Z-20090615T115000Z
Rate-Control: no
PLAY rtsp://192.168.0.1/path/to/recording RTSP/1.0
Cseq: 123
Session: 12345678
Require: onvif-replay
Range: clock=20090615T115000.440Z-20090615T114900Z
Rate-Control: no
Scale: -1.0
        </programlisting>
      </section>
      <section xml:id="_Ref244047237">
        <title>Rate-Control header field</title>
        <para>This specification introduces the Rate-Control header field, which may be either “yes” or “no”. If the field is not present, “yes” is assumed, and the stream is delivered in real time using standard RTP timing mechanisms. If this field is “no”, the stream is delivered as fast as possible, using only the flow control provided by the transport to limit the delivery rate.</para>
        <para>The important difference between these two modes is that with “Rate-Control=yes”, the server is in control of the playback speed, whereas with “Rate-Control=no” the client is in control of the playback speed. Rate-controlled replay will typically only be used by non-ONVIF specific clients as they will not specify “Rate-Control=no”.</para>
        <para>When replaying multiple tracks of a single recording, started by a single RTSP PLAY command and not using rate-control, the data from the tracks should be multiplexed in time in the same order as they were recorded.</para>
        <para>An ONVIF compliant RTSP server shall support operation with “Rate-Control=no” for playback.</para>
      </section>
      <section>
        <title>Frames header field</title>
        <para>The Frames header field may be used to reduce the number of frames that are transmitted, for example to lower bandwidth or processing load. Three modes are possible:</para>
        <orderedlist>
          <listitem>
            <para>Intra frames only. This is indicated using the value “intra”, optionally followed by a minimum interval between successive intra frames in the stream. The latter can be used to limit the number of frames received even in the presence of “I-frame storms” caused by many receivers requesting frequent I-frames.</para>
          </listitem>
          <listitem>
            <para>Intra frames and predicted frames only. This is indicated using the value “predicted”. This value can be used to eliminate B-frames if the stream includes them.</para>
          </listitem>
          <listitem>
            <para>All frames. This is the default.</para>
          </listitem>
        </orderedlist>
        <para>
          <emphasis role="bold">Examples:</emphasis>
        </para>
        <para>To request intra frames only:</para>
        <programlisting>Frames: intra</programlisting>
        <para>To request intra frames with a minimum interval of 4000 milliseconds:</para>
        <programlisting>Frames: intra/4000</programlisting>
        <para>To request intra frames and predicted frames only:</para>
        <programlisting>Frames: predicted</programlisting>
        <para>To request all frames (note that it is not necessary to explicitly specify this mode but the example is included for completeness):</para>
        <programlisting>Frames: all</programlisting>
        <para>The interval argument used with the “intra” option refers to the recording timeline, not playback time; thus for any given interval the same frames are played regardless of playback speed. The interval argument shall NOT be present unless the Frames option is “intra”.</para>
        <para>The server shall support the Frames header field. This does not preclude the use of the Scale header field as an alternative means of limiting the data rate. The implementation of the Scale header field may vary between different server implementations, as stated by [RFC 2326].</para>
        <para>An ONVIF compliant RTSP server shall support the Frames parameters “intra” and “all” for playback.</para>
      </section>
      <section>
        <title>Synchronization points</title>
        <para>The transmitted video stream shall begin at a synchronization point (see section “Synchronization Point” of the ONVIF Media Service Specificaton). The rules for choosing the starting frame are as follows:</para>
        <itemizedlist>
          <listitem>
            <para>If the requested start time is within a section of recorded footage, the stream starts with the first clean point at or before the requested start time. This is the case regardless of playback direction.</para>
          </listitem>
          <listitem>
            <para>If the requested start time is within a gap in recorded footage and playback is being initiated in the forwards direction, the stream starts with the first clean point in the section following the requested start time.</para>
          </listitem>
          <listitem>
            <para>If the requested start time is within a gap in recorded footage and playback is being initiated in the reverse direction, the stream starts with the last clean point in the section preceding the requested start time.</para>
          </listitem>
        </itemizedlist>
      </section>
    </section>
    <section xml:id="_Ref229292321">
      <title>Reverse replay</title>
      <para>Reverse replay is initiated using the Scale header field with a negative value as described above.</para>
      <section>
        <title>Packet transmission order</title>
        <para>The example in <xref linkend="_Ref462901590" /> shows how frames are transmitted during normal forward playback for a recording with two short video clips each consisting of two GOPs. As shown all packets are transmitted in recording order. The last frame before a gap is marked with the E flag to signal a gap in the recording. </para>
        <figure xml:id="_Ref462901590">
          <title>Packet transmission during forward playback</title>
          <mediaobject>
          <imageobject>
            <imagedata fileref="media/Streaming/image6.svg" contentwidth="97.4mm" contentdepth="84.9mm" />
          </imageobject>
        </mediaobject>
        </figure>
        <para>The order in which video packets are transmitted during reverse replay is based on GOPs, where a GOP consists of a clean point followed by a sequence of non-cleanpoint packets.</para>
        <para>During reverse playback, GOPs shall be sent in reverse order, but packets within a GOP shall be sent in forward order. The first packet of each GOP shall have the “discontinuity” bit set in its RTP extension header. The last frame of a GOP immediately following a gap (or the beginning of available footage) shall have the E bit set in its RTP extension header.</para>
        <para>When transmitting only key frames, or when the codec is not motion-based (e.g. JPEG), a GOP is considered to consist of a single frame, but may still be composed of multiple packets. In this case the packets within each frame shall be again sent in forward order, while the frames themselves shall be sent in reverse order.</para>
        <para>Audio and metadata streams MAY be transmitted in an order mirroring that of the video stream. Thus packets from these streams are sent in forward playback order until the occurrence of a packet (generally a video packet) with the D bit set in the extension header, at which point they jump back to a point before the discontinuity.</para>
        <para>Note that reverse playback of Audio packet isn’t useful. Threfore Audio packets should generally not be transmitted during reverse playback.</para>
        <para>The example of <xref linkend="_Ref462845433" /> shows for the same recording as depicted in <xref linkend="_Ref462901590" /> how packets are transmitted during reverse forward playback. As shown all packets are transmitted in recording order. </para>
        <figure xml:id="_Ref462845433">
          <title>Packet transmission during reverse playback</title>
          <mediaobject>
            <imageobject>
              <imagedata fileref="media/Streaming/image7.svg" contentwidth="85.5mm"/>
            </imageobject>
          </mediaobject>
        </figure>
      </section>
      <section>
        <title>RTP sequence numbers</title>
        <para>The RTP sequence numbers of packets transmitted during reverse playback shall increment monotonically <emphasis>in the order of delivery</emphasis>, not in the intended order of playback.</para>
      </section>
      <section>
        <title>RTP timestamps</title>
        <para>The use of RTP timestamps depends on the value of the Rate-Control header. If the value of this header is “no” (i.e. the client controls playback speed), the RTP timestamps are derived from the original sampling times of the recorded frames. If the Rate-Control header is not present or has the value “yes” (i.e. the server controls playback speed), the RTP timestamps correspond to playback timing as described in [RFC 2326] Appendix B.</para>
        <para>If Rate-Control is “no”, the RTP timestamps of packets transmitted during reverse playback shall be the same as they would be if those same packets were being transmitted in the forwards direction. Unlike the sequence numbers, the RTP timestamps correspond to the original recording order, not the delivery order. The server MAY use the same RTP timestamps that were originally received when the stream was recorded.</para>
        <para>This means that successive RTP packets of a single GOP will always have increasing RTP timestamps (see transmission order above), but that the timestamp on index frames of successively received GOPs will decrease during reverse replay.</para>
        <para>If Rate-Control is “yes”, the RTP timestamps of packets transmitted during reverse playback shall indicate the times at which each frame should be rendered at the client. Thus successive packets of a single GOP will have <emphasis>decreasing</emphasis> RTP timestamps (since the first one delivered should be played last), and the timestamps on index frames will <emphasis>increase</emphasis>. In this mode the interval between successive timestamps depends on the values of the Speed and Scale headers, as described in [RFC 2326] Appendix B.</para>
        <para>Note that strict decreasing order of RTP timestamps does not apply for GOPs with B-Frames.</para>
      </section>
    </section>
    <section>
      <title>RTSP Keepalive</title>
      <para>When rate control is disabled and the RTP stream is tunneled through the RTSP connection (i.e. using the RTP/RTSP/TCP or RTP/RTSP/HTTP/TCP transports), the client must be aware that it may not be able to receive the response to any request if for example replay is paused.</para>
    </section>
    <section>
      <title>Currently recording footage</title>
      <para>If the client commences playback from the current real world time or shortly before it, it can end up playing footage in real time as it is being recorded. In this event the server simply continues to send stream data to the client as it receives it.</para>
      <para>Note that the E bit is not set on access units currently being recorded even though each access unit sent to the replay client will typically be the last one known to the server. If recording stops however, the E bit is set on the last access unit of the recording.</para>
    </section>
    <section>
      <title>End of footage</title>
      <para>If playback reaches a point after which there is no further data in one or more of the streams being sent, it stops transmitting data but does not enter the “paused” state. If the server resumes recording after this has happened, delivery will resume with the new data as it is received.</para>
    </section>
    <section>
      <title>Go To Time</title>
      <para>As stated in [RFC 2326] section 10.5, a PLAY command received when replay is already in progress will not take effect until the existing play operation has completed. This specification adds a new RTSP header, “Immediate”, which overrides this behaviour for the PLAY command that it is used with:</para>
      <programlisting>
PLAY rtsp://192.168.0.1/path/to/recording RTSP/1.0
CSeq: 123
Session: 12345678
Require: onvif-replay
Range: clock=20090615T114900.440Z-
Rate-Control: no
Immediate: yes</programlisting>
      <para>If the server receives a PLAY command with the Immediate header set to “yes”, it will immediately start playing from the new location, cancelling any existing PLAY command. The first packet sent from the new location shall have the D (discontinuity) bit set in its RTP extension header.</para>
      <para>An ONVIF compliant RTSP server shall support the immediate header field for playback with value “yes”. The behavior without immediate header or value “no” is not defined by the specification.</para>
    </section>
    <section>
      <title>Use of  RTCP</title>
      <para>A server is not required to send RTCP packets. If it does send them, the following rules apply:</para>
      <para>If Rate Control is enabled (see section <xref linkend="_Ref244047237" />), RTCP packets shall be constructed and transmitted as specified in [RFC 3550]. In particular, the NTP timestamp in a sender report indicates the current wallclock time, and is not related to the NTP timestamps embedded in the RTP extension headers in the data streams.</para>
      <para>If Rate Control is not enabled, both the NTP timestamp and RTP timestamp in each sender report shall be set to zero.</para>
    </section>
  </chapter>
  <chapter>
    <title>WebSocket transport for RTP/RTSP/TCP</title>
    <para>WebSocket protocol basically provides bidirectional communication between Client and Server for web application. This section describes how a WebSocket connection can be established between a client and a server. The connection handling is done using WebSocket [RFC 6455]. </para>
    <para>The WebSocket transport mechanism explained in the <xref linkend="_Ref474397092" /> is common for live streaming and playback. The RTP/RTSP/TCP data transmitted by the device over the WebSocket shall follow the device requirements as explained in Section <xref linkend="_Toc208657708" /> Live Streaming and Section <xref linkend="_Ref279441431" /> Playback.</para>
    <figure xml:id="_Ref474397092">
      <title>Streaming over WebSocket</title>
      <mediaobject>
        <imageobject>
          <imagedata fileref="media/Streaming/websocket.svg" contentwidth="160.6mm" />
        </imageobject>
      </mediaobject>
    </figure>
    <section>
      <title>WebSocket version </title>
      <para>The Device shall support WebSocket protocol version 13.</para>
    </section>
    <section>
      <title>Authentication</title>
      <para>The device shall follow RTSP authentication requirements as explained in Section 5.12.1 Authentication of ONVIF Core Specification. The access class of streams shall be READ_MEDIA.</para>
    </section>
    <section>
      <title>WebSocket Connection </title>
      <para> The initial connection setup is done in two steps:</para>
      <orderedlist>
        <listitem>
          <para>Handshake</para>
        </listitem>
        <listitem>
          <para>Data Transfer</para>
        </listitem>
      </orderedlist>
      <section>
        <title>Handshake</title>
        <section>
          <title>WebSocket Subprotocol</title>
          <para>The device shall support the WebSocket subprotocol as defined in Section 1.9 of [RFC 6455]. The websocket sub protocol defined by this specification is identified with 'rtsp.onvif.org'. A device shall support the 'rtsp.onvif.org' sub protocol.</para>
        </section>
        <section>
          <title>Example: WebSocket Handshake</title>
          <para>This example shows the message transfer between an Web client (client) and an Web server (server). The client requests server to initiate a WebSocket connection using the WebSocket URI. The WebSocket Uri can be retrieved using the GetServiceCapabilities command of the ONVIF Media2 Service. An example WebSocket URI may look like, “ws:/webSocketServer”</para>
          <programlisting><![CDATA[client->server:  	GET /webSocketServer HTTP/1.1
Host: 192.168.0.1
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==
Origin: http://example.com
Sec-WebSocket-Protocol: rtsp.onvif.org
Sec-WebSocket-Version: 13
server->client:	HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo=
Sec-WebSocket-Protocol: rtsp.onvif.org
]]></programlisting>
        </section>
      </section>
      <section>
        <title>Data Transfer</title>
        <para>After a successful handshake, client and server can transfer bidirectional data over WebSocket connection.</para>
        <para>Device supporting live streaming and playback streaming over WebSocket provides the WebSocket streaming URI in the GetServiceCapabilities of Media2 Service Section 5.11 and Replay Service  Section 5.4.1 respectively.</para>
        <section>
          <title>WebSocket Message Frame Format</title>
          <para>The basic units of data transmitted over WebSocket connection are referred as “messages” in the RFC 6455. The messages are composed of one or more frames and each frame has an associated data type. There are different type of frames like text frames and data frames.</para>
          <para>The device shall only use  data frames for transmitting the RTP/RTSP/TCP data over the WebSocket.</para>
        </section>
      </section>
    </section>
  </chapter>
  <appendix role="revhistory">
    <title>Revision History</title>
    <para />
  </appendix>
</book>
